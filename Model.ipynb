{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>webTitle</th>\n",
       "      <th>webUrl</th>\n",
       "      <th>bodyContent</th>\n",
       "      <th>webPublicationDate</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us-news/2016/jan/31/iowa-caucus-underdog-candi...</td>\n",
       "      <td>US news</td>\n",
       "      <td>Iowa underdogs put on brave faces despite all ...</td>\n",
       "      <td>https://www.theguardian.com/us-news/2016/jan/3...</td>\n",
       "      <td>As polling day looms and the cameras turn only...</td>\n",
       "      <td>2016-01-31T23:53:37Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us-news/2016/jan/31/iowa-caucus-worlds-most-pa...</td>\n",
       "      <td>US news</td>\n",
       "      <td>Iowa caucus: hologram eagle and Jesus star on ...</td>\n",
       "      <td>https://www.theguardian.com/us-news/2016/jan/3...</td>\n",
       "      <td>In Des Moines on Sunday, the Guardian was give...</td>\n",
       "      <td>2016-01-31T23:46:28Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world/2016/jan/31/tanzania-britsh-helicopter-p...</td>\n",
       "      <td>World news</td>\n",
       "      <td>British pilot in Tanzania 'manoeuvred ​to save...</td>\n",
       "      <td>https://www.theguardian.com/world/2016/jan/31/...</td>\n",
       "      <td>A British pilot who was shot dead by an elepha...</td>\n",
       "      <td>2016-01-31T23:43:48Z</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>football/2016/jan/31/late-winner-gets-usa-off-...</td>\n",
       "      <td>Football</td>\n",
       "      <td>USA 3-2 Iceland | International friendly match...</td>\n",
       "      <td>https://www.theguardian.com/football/2016/jan/...</td>\n",
       "      <td>USA took a step toward shaking off the ghosts ...</td>\n",
       "      <td>2016-01-31T23:30:49Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>football/2016/jan/31/blackburn-paul-lambert-ox...</td>\n",
       "      <td>Football</td>\n",
       "      <td>Reinvigorated Paul Lambert reflects after impr...</td>\n",
       "      <td>https://www.theguardian.com/football/2016/jan/...</td>\n",
       "      <td>The clean-shaven, spectacle free and suspiciou...</td>\n",
       "      <td>2016-01-31T22:30:10Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          article_id sectionName  \\\n",
       "0  us-news/2016/jan/31/iowa-caucus-underdog-candi...     US news   \n",
       "1  us-news/2016/jan/31/iowa-caucus-worlds-most-pa...     US news   \n",
       "2  world/2016/jan/31/tanzania-britsh-helicopter-p...  World news   \n",
       "3  football/2016/jan/31/late-winner-gets-usa-off-...    Football   \n",
       "4  football/2016/jan/31/blackburn-paul-lambert-ox...    Football   \n",
       "\n",
       "                                            webTitle  \\\n",
       "0  Iowa underdogs put on brave faces despite all ...   \n",
       "1  Iowa caucus: hologram eagle and Jesus star on ...   \n",
       "2  British pilot in Tanzania 'manoeuvred ​to save...   \n",
       "3  USA 3-2 Iceland | International friendly match...   \n",
       "4  Reinvigorated Paul Lambert reflects after impr...   \n",
       "\n",
       "                                              webUrl  \\\n",
       "0  https://www.theguardian.com/us-news/2016/jan/3...   \n",
       "1  https://www.theguardian.com/us-news/2016/jan/3...   \n",
       "2  https://www.theguardian.com/world/2016/jan/31/...   \n",
       "3  https://www.theguardian.com/football/2016/jan/...   \n",
       "4  https://www.theguardian.com/football/2016/jan/...   \n",
       "\n",
       "                                         bodyContent    webPublicationDate  id  \n",
       "0  As polling day looms and the cameras turn only...  2016-01-31T23:53:37Z   1  \n",
       "1  In Des Moines on Sunday, the Guardian was give...  2016-01-31T23:46:28Z   2  \n",
       "2  A British pilot who was shot dead by an elepha...  2016-01-31T23:43:48Z   3  \n",
       "3  USA took a step toward shaking off the ghosts ...  2016-01-31T23:30:49Z   4  \n",
       "4  The clean-shaven, spectacle free and suspiciou...  2016-01-31T22:30:10Z   5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data = pd.read_csv('guardian_articles.csv')\n",
    "news_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149839.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>74920.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43254.93783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37460.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74920.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112379.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>149839.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id\n",
       "count  149839.00000\n",
       "mean    74920.00000\n",
       "std     43254.93783\n",
       "min         1.00000\n",
       "25%     37460.50000\n",
       "50%     74920.00000\n",
       "75%    112379.50000\n",
       "max    149839.00000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149839 entries, 0 to 149838\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   article_id          149839 non-null  object\n",
      " 1   sectionName         149839 non-null  object\n",
      " 2   webTitle            149839 non-null  object\n",
      " 3   webUrl              149839 non-null  object\n",
      " 4   bodyContent         148731 non-null  object\n",
      " 5   webPublicationDate  149839 non-null  object\n",
      " 6   id                  149839 non-null  int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "news_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.drop(columns=[\"article_id\",\"webUrl\",\"webPublicationDate\",\"id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_single_letters(sentence):\n",
    "    words = sentence.split()\n",
    "    filtered_words = [word for word in words if len(word) > 1 or not word.isalpha()]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(remove_single_letters(text.lower()))\n",
    "    filtered_tokens = [stemmer.stem(token) for token in tokens if (token not in stop_words and token.isalpha())]\n",
    "    return filtered_tokens\n",
    "\n",
    "num_sections = news_data['sectionName'].nunique()\n",
    "samples_per_group = 20000 // num_sections\n",
    "\n",
    "sampled_news_data = news_data.groupby('sectionName').apply(lambda x: x.sample(min(samples_per_group, len(x)))).reset_index(drop=True)\n",
    "\n",
    "\n",
    "sampled_news_data=sampled_news_data[sampled_news_data['bodyContent'].apply(lambda x: not isinstance(x, float))]\n",
    "sampled_news_data['tokens'] = sampled_news_data['bodyContent'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sectionName</th>\n",
       "      <th>webTitle</th>\n",
       "      <th>bodyContent</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A time for Japan</td>\n",
       "      <td>From polo shirts to retro wristwatches: how to...</td>\n",
       "      <td>Remember when Mad Men started airing on televi...</td>\n",
       "      <td>[rememb, mad, men, start, air, televis, indoor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A vision for better food</td>\n",
       "      <td>‘Cooking is at the centre of life’: food entre...</td>\n",
       "      <td>For a man at the head of a food empire whose a...</td>\n",
       "      <td>[man, head, food, empir, whose, annual, sale, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMC+: Only the good stuff</td>\n",
       "      <td>What TV series should you watch next? Take our...</td>\n",
       "      <td>There’s nothing better than settling in with a...</td>\n",
       "      <td>[noth, better, settl, excel, new, tv, seri, es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>About</td>\n",
       "      <td>Guardian and Observer style guide: A</td>\n",
       "      <td>A B C D E F G H I J K L M N O P Q R S T U V W ...</td>\n",
       "      <td>[h, use, silent, h, heir, hour, honest, politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon Prime Video: Truth Seekers</td>\n",
       "      <td>Scarily funny: Frost and Pegg return to comedy...</td>\n",
       "      <td>British writer-actors Nick Frost and Simon Peg...</td>\n",
       "      <td>[british, nick, frost, simon, pegg, fear, dedi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sectionName  \\\n",
       "0                   A time for Japan   \n",
       "1           A vision for better food   \n",
       "2          AMC+: Only the good stuff   \n",
       "3                              About   \n",
       "4  Amazon Prime Video: Truth Seekers   \n",
       "\n",
       "                                            webTitle  \\\n",
       "0  From polo shirts to retro wristwatches: how to...   \n",
       "1  ‘Cooking is at the centre of life’: food entre...   \n",
       "2  What TV series should you watch next? Take our...   \n",
       "3               Guardian and Observer style guide: A   \n",
       "4  Scarily funny: Frost and Pegg return to comedy...   \n",
       "\n",
       "                                         bodyContent  \\\n",
       "0  Remember when Mad Men started airing on televi...   \n",
       "1  For a man at the head of a food empire whose a...   \n",
       "2  There’s nothing better than settling in with a...   \n",
       "3  A B C D E F G H I J K L M N O P Q R S T U V W ...   \n",
       "4  British writer-actors Nick Frost and Simon Peg...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [rememb, mad, men, start, air, televis, indoor...  \n",
       "1  [man, head, food, empir, whose, annual, sale, ...  \n",
       "2  [noth, better, settl, excel, new, tv, seri, es...  \n",
       "3  [h, use, silent, h, heir, hour, honest, politi...  \n",
       "4  [british, nick, frost, simon, pegg, fear, dedi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_news_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class AutoencoderModule(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, activation):\n",
    "        super(AutoencoderModule, self).__init__()\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        # Extend for other activations if needed\n",
    "        \n",
    "        self.encoder = nn.Linear(input_dim, latent_dim)\n",
    "        self.decoder = nn.Linear(latent_dim, input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.encoder(x))\n",
    "        x = self.activation(self.decoder(x))\n",
    "        return x\n",
    "\n",
    "class Autoencoder:\n",
    "    def __init__(self, latent_dim=32, activation='relu', epochs=200, batch_size=128):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.activation = activation\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = None\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.optimizer = None\n",
    "        self.his = []\n",
    "\n",
    "    def fit(self, X):\n",
    "        if self.model is None:\n",
    "            self.model = AutoencoderModule(X.shape[1], self.latent_dim, self.activation)\n",
    "            self.optimizer = optim.Adam(self.model.parameters())\n",
    "        \n",
    "        dataset = torch.utils.data.TensorDataset(torch.tensor(X, dtype=torch.float32))\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        X_train, X_test = train_test_split(X, test_size=0.2)\n",
    "        \n",
    "        train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32))\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        test_dataset = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.float32))\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for batch in train_loader:\n",
    "                inputs = batch[0]\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs, inputs)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "            # Validation loss\n",
    "            with torch.no_grad():\n",
    "                val_loss = sum(self.loss_fn(self.model(inputs), inputs) for inputs, in test_loader)\n",
    "                self.his.append(val_loss / len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
